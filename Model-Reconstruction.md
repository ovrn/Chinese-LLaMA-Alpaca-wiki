In order to merge the LoRA model with the original LLaMA, two methods are currently provided:

- Online conversion: suitable for Google Colab users, can use notebook for online conversion and model quantization.
  - Link: [https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/Online-conversion-with-Colab](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/Online-conversion-with-Colab)
- Manual conversion: suitable for offline conversion, generates models in different formats for quantization or further fine-tuning.
  - Link: [https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/Manual-Conversion](https://github.com/ymcui/Chinese-LLaMA-Alpaca/wiki/Manual-Conversion)